{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 880/880 [00:37<00:00, 23.53it/s]\n"
     ]
    }
   ],
   "source": [
    "directory = \"../datasets/realWorld\"\n",
    "\n",
    "obls = [\"chest\", \"forearm\", \"head\", \"shin\", \"upperarm\", \"waist\", \"thigh\"]\n",
    "activities = [\"running\", \"jumping\", \"climbingdown\", \"climbingup\", \"walking\", \"lying\", \"sitting\", \"standing\"]\n",
    "obls_map = {\"chest\":0, \"forearm\":1, \"head\":2, \"shin\":3, \"upperarm\":4, \"waist\":5, \"thigh\":6}\n",
    "activities_map = {\"running\":0, \"jumping\":1, \"climbingdown\":2, \"climbingup\":3, \"walking\":4, \"lying\":5, \"sitting\":6, \"standing\":7}\n",
    "\n",
    "def nameToIndex(obl, act):\n",
    "    index = obls_map[obl]*len(activities_map) + activities_map[act]\n",
    "    return index\n",
    "\n",
    "def indexToName(index):\n",
    "    obl = index//len(activities_map)\n",
    "    act = index%len(activities_map)\n",
    "    return obls[obl] + \"_\" +  activities[act]\n",
    "\n",
    "\n",
    "file_names = list()\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    \n",
    "    if not (dirs):\n",
    "        csv_files = [os.path.join(subdir, f) for f in files if \".csv\" in f]\n",
    "        file_names = file_names + csv_files\n",
    "\n",
    "\n",
    "file_names = (file_names)\n",
    "parsed_files = list()\n",
    "parsed_targets = list()\n",
    "for obl in obls:\n",
    "    obl_files = [f for f in file_names if obl in f]\n",
    "    for activity in activities:\n",
    "        obl_activity_files = [f for f in obl_files if activity in f]\n",
    "        parsed_files = parsed_files + obl_activity_files\n",
    "        target_classes = [nameToIndex(obl,activity)]*len(obl_activity_files)\n",
    "        parsed_targets = parsed_targets + target_classes\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# lets just assume 50Hz and no resampling, the error this causes is minimal\n",
    "samples_len = 50*2 #seconds\n",
    "Acc_x = list()\n",
    "Acc_y = list()\n",
    "Acc_z = list()\n",
    "Label = list()\n",
    "for data in tqdm(zip(parsed_files,parsed_targets),total=len(parsed_targets)):\n",
    "    csv, target = data\n",
    "    csv_part = pd.read_csv(csv)\n",
    "    for i in range(0,int(csv_part.shape[0]/samples_len)):\n",
    "        sample = csv_part.iloc[i*samples_len:(i+1)*samples_len]\n",
    "        sample_x = sample[\"attr_x\"].reset_index(drop=True) \n",
    "        sample_y = sample[\"attr_y\"].reset_index(drop=True) \n",
    "        sample_z = sample[\"attr_z\"].reset_index(drop=True)\n",
    "        sample_label = pd.DataFrame([target])\n",
    "\n",
    "        Acc_x.append(sample_x)\n",
    "\n",
    "        Acc_y.append(sample_y)\n",
    "        Acc_z.append(sample_z)\n",
    "        Label.append(sample_label)\n",
    "Acc_x = pd.concat(Acc_x, ignore_index=True, axis=1).transpose()\n",
    "Acc_y = pd.concat(Acc_y, ignore_index=True, axis=1).transpose()\n",
    "Acc_z = pd.concat(Acc_z, ignore_index=True, axis=1).transpose()\n",
    "Label = pd.concat(Label, ignore_index=True, axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_names = list()\n",
    "for i in range(len(obls_map)*len(activities_map)):  \n",
    "    joint_names.append(indexToName(i))\n",
    "Label_names = pd.DataFrame(joint_names, columns=[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Acc_x.to_csv(\"../datasets/RW16/train/Acc_x.txt\", index=False, header=False, sep=\" \")\n",
    "Acc_y.to_csv(\"../datasets/RW16/train/Acc_y.txt\", index=False, header=False, sep=\" \")\n",
    "Acc_z.to_csv(\"../datasets/RW16/train/Acc_z.txt\", index=False, header=False, sep=\" \")\n",
    "Label.to_csv(\"../datasets/RW16/train/Label.txt\", index=False, header=False, sep=\" \")\n",
    "Label_names.to_csv(\"../datasets/RW16/Label_names.txt\", index=False, header=False, sep=\" \")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
